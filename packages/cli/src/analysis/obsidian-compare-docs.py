#!/usr/bin/env python3
"""
Obsidian: Document Comparison Tool
Compares two documents and shows similarities/differences
"""

import sys
import os
import requests
import difflib
from pathlib import Path
from collections import Counter
import re

OLLAMA_URL = "http://127.0.0.1:11434/api/embeddings"


def read_document(file_path):
    """Read document content"""
    try:
        with open(file_path, "r", encoding="utf-8") as f:
            return f.read()
    except Exception:
        return None


def extract_metadata(content):
    """Extract metadata from document"""
    lines = content.split("\n")

    # Title (first h1)
    title = None
    for line in lines:
        if line.startswith("# "):
            title = line[2:].strip()
            break

    # Headings
    headings = []
    for line in lines:
        if line.startswith("##"):
            h = line.lstrip("#").strip()
            if h:
                headings.append(h)

    # Tags
    tags = re.findall(r"#(\w+)", content)

    # Links
    links = re.findall(r"\[\[([^\]]+)\]\]", content)

    # Word count
    words = len(content.split())

    return {
        "title": title or "Untitled",
        "headings": headings,
        "tags": list(set(tags)),
        "links": list(set(links)),
        "word_count": words,
        "lines": len(lines),
    }


def get_embedding(text):
    """Get embedding for text"""
    try:
        response = requests.post(
            OLLAMA_URL, json={"model": "bge-m3", "prompt": text[:2000]}, timeout=30  # Limit length
        )
        return response.json()["embedding"]
    except Exception:
        return None


def cosine_similarity(vec1, vec2):
    """Calculate cosine similarity"""
    if not vec1 or not vec2:
        return 0.0

    dot_product = sum(a * b for a, b in zip(vec1, vec2))
    magnitude1 = sum(a * a for a in vec1) ** 0.5
    magnitude2 = sum(b * b for b in vec2) ** 0.5

    if magnitude1 == 0 or magnitude2 == 0:
        return 0.0

    return dot_product / (magnitude1 * magnitude2)


def extract_key_phrases(content):
    """Extract key phrases (simple word frequency)"""
    # Remove markdown syntax
    text = re.sub(r"[#*`\[\]()]", "", content)
    words = text.lower().split()

    # Filter stop words (simple)
    stop_words = {
        "a",
        "an",
        "the",
        "and",
        "or",
        "but",
        "in",
        "on",
        "at",
        "to",
        "for",
        "of",
        "with",
        "by",
        "from",
        "as",
        "is",
        "was",
        "are",
        "were",
        "be",
        "been",
        "being",
        "ì´",
        "ê·¸",
        "ì €",
        "ê²ƒ",
        "ìˆ˜",
        "ë“±",
        "ë°",
    }

    filtered = [w for w in words if len(w) > 2 and w not in stop_words]

    # Count frequency
    counter = Counter(filtered)
    return counter.most_common(15)


def compare_content(content1, content2):
    """Compare content using difflib"""
    lines1 = content1.split("\n")
    lines2 = content2.split("\n")

    matcher = difflib.SequenceMatcher(None, lines1, lines2)
    ratio = matcher.ratio()

    # Find common lines
    common = []
    for block in matcher.get_matching_blocks():
        if block.size > 0:
            common.extend(lines1[block.a : block.a + block.size])

    return {
        "similarity_ratio": ratio,
        "common_lines": len(common),
        "total_lines": max(len(lines1), len(lines2)),
    }


def main():
    if len(sys.argv) < 3:
        print("âŒ ë‘ ê°œì˜ íŒŒì¼ ê²½ë¡œê°€ í•„ìš”í•©ë‹ˆë‹¤")
        print("Usage: obsidian-compare-docs.py <file1> <file2>")
        sys.exit(1)

    file1 = sys.argv[1]
    file2 = sys.argv[2]

    # Unescape paths if needed
    for i, f in enumerate([file1, file2]):
        if "\\/" in f:
            f = f.replace("\\/", "/")
            f = f.replace("\\-", "-")
            f = f.replace("\\ ", " ")
            if i == 0:
                file1 = f
            else:
                file2 = f

    # Check files exist
    if not os.path.exists(file1):
        print(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file1}")
        sys.exit(1)

    if not os.path.exists(file2):
        print(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file2}")
        sys.exit(1)

    # Read documents
    content1 = read_document(file1)
    content2 = read_document(file2)

    if not content1 or not content2:
        print("âŒ íŒŒì¼ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        sys.exit(1)

    print("ğŸ“Š ë¬¸ì„œ ë¹„êµ ë¶„ì„")
    print("=" * 60)
    print()

    # Extract metadata
    meta1 = extract_metadata(content1)
    meta2 = extract_metadata(content2)

    print(f"ğŸ“„ ë¬¸ì„œ 1: {meta1['title']}")
    print(f"   ë‹¨ì–´: {meta1['word_count']}, ì¤„: {meta1['lines']}")
    print(
        f"   í—¤ë”©: {len(meta1['headings'])}, íƒœê·¸: {len(meta1['tags'])}, ë§í¬: {len(meta1['links'])}"
    )
    print()

    print(f"ğŸ“„ ë¬¸ì„œ 2: {meta2['title']}")
    print(f"   ë‹¨ì–´: {meta2['word_count']}, ì¤„: {meta2['lines']}")
    print(
        f"   í—¤ë”©: {len(meta2['headings'])}, íƒœê·¸: {len(meta2['tags'])}, ë§í¬: {len(meta2['links'])}"
    )
    print()
    print("=" * 60)

    # Semantic similarity
    print()
    print("ğŸ” ì˜ë¯¸ë¡ ì  ìœ ì‚¬ë„ ë¶„ì„ ì¤‘...")

    emb1 = get_embedding(content1)
    emb2 = get_embedding(content2)

    if emb1 and emb2:
        similarity = cosine_similarity(emb1, emb2)
        print(f"   ìœ ì‚¬ë„: {similarity:.3f} ({int(similarity * 100)}%)")

        if similarity > 0.8:
            print("   âœ… ë§¤ìš° ìœ ì‚¬í•œ ë¬¸ì„œì…ë‹ˆë‹¤")
        elif similarity > 0.6:
            print("   âœ… ìœ ì‚¬í•œ ì£¼ì œë¥¼ ë‹¤ë£¨ê³  ìˆìŠµë‹ˆë‹¤")
        elif similarity > 0.4:
            print("   âš ï¸  ì¼ë¶€ ê´€ë ¨ì„±ì´ ìˆìŠµë‹ˆë‹¤")
        else:
            print("   âŒ ì„œë¡œ ë‹¤ë¥¸ ì£¼ì œì…ë‹ˆë‹¤")
    else:
        print("   âš ï¸  ìœ ì‚¬ë„ ê³„ì‚° ì‹¤íŒ¨")

    # Content comparison
    print()
    print("ğŸ“ ë‚´ìš© ë¹„êµ...")
    comp = compare_content(content1, content2)
    print(f"   í…ìŠ¤íŠ¸ ì¼ì¹˜ìœ¨: {int(comp['similarity_ratio'] * 100)}%")
    print(f"   ê³µí†µ ì¤„: {comp['common_lines']}/{comp['total_lines']}")

    # Shared tags
    print()
    print("ğŸ·ï¸  ê³µí†µ íƒœê·¸:")
    common_tags = set(meta1["tags"]) & set(meta2["tags"])
    if common_tags:
        print(f"   {', '.join('#' + t for t in common_tags)}")
    else:
        print("   (ì—†ìŒ)")

    # Shared links
    print()
    print("ğŸ”— ê³µí†µ ë§í¬:")
    common_links = set(meta1["links"]) & set(meta2["links"])
    if common_links:
        for link in list(common_links)[:5]:
            print(f"   â€¢ [[{link}]]")
        if len(common_links) > 5:
            print(f"   ... +{len(common_links) - 5}ê°œ ë”")
    else:
        print("   (ì—†ìŒ)")

    # Key phrases
    print()
    print("ğŸ’¡ ì£¼ìš” í‚¤ì›Œë“œ ë¹„êµ:")

    phrases1 = extract_key_phrases(content1)
    phrases2 = extract_key_phrases(content2)

    words1 = {word for word, _ in phrases1}
    words2 = {word for word, _ in phrases2}
    common_words = words1 & words2

    print()
    print("   ê³µí†µ í‚¤ì›Œë“œ:")
    if common_words:
        print(f"   {', '.join(list(common_words)[:10])}")
    else:
        print("   (ì—†ìŒ)")

    print()
    print("   ë¬¸ì„œ 1 ê³ ìœ :")
    unique1 = [w for w, _ in phrases1[:5] if w not in words2]
    if unique1:
        print(f"   {', '.join(unique1)}")
    else:
        print("   (ì—†ìŒ)")

    print()
    print("   ë¬¸ì„œ 2 ê³ ìœ :")
    unique2 = [w for w, _ in phrases2[:5] if w not in words1]
    if unique2:
        print(f"   {', '.join(unique2)}")
    else:
        print("   (ì—†ìŒ)")

    # Suggestions
    print()
    print("=" * 60)
    print("ğŸ’¡ ì œì•ˆ:")
    print()

    if similarity and similarity > 0.7:
        print("â€¢ ë¬¸ì„œê°€ ë§¤ìš° ìœ ì‚¬í•©ë‹ˆë‹¤. í•˜ë‚˜ë¡œ í•©ì¹˜ëŠ” ê²ƒì„ ê³ ë ¤í•˜ì„¸ìš”")
        print("â€¢ ë˜ëŠ” í•˜ë‚˜ë¥¼ ë‹¤ë¥¸ í•˜ë‚˜ì˜ í•˜ìœ„ ë¬¸ì„œë¡œ ì¬êµ¬ì„±í•˜ì„¸ìš”")
    elif similarity and similarity > 0.4:
        print("â€¢ ê´€ë ¨ëœ ë‚´ìš©ì´ ìˆìŠµë‹ˆë‹¤. ìƒí˜¸ ì°¸ì¡° ë§í¬ë¥¼ ì¶”ê°€í•˜ì„¸ìš”")
        print(f"  ì˜ˆ: [[{Path(file1).stem}]], [[{Path(file2).stem}]]")
    else:
        print("â€¢ ì„œë¡œ ë‹¤ë¥¸ ì£¼ì œë¥¼ ë‹¤ë£¨ê³  ìˆìŠµë‹ˆë‹¤")
        print("â€¢ í•˜ë‚˜ì˜ MOC(Map of Content)ë¡œ ì—°ê²°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤")

    if common_tags:
        print(f"â€¢ ê³µí†µ íƒœê·¸ {len(common_tags)}ê°œë¡œ ì—°ê²°ë˜ì–´ ìˆìŠµë‹ˆë‹¤")

    print()


if __name__ == "__main__":
    main()
